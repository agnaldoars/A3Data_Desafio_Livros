# EDA_NLP
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from textblob import TextBlob
from wordcloud import WordCloud
import ast

nltk.download("punkt")
nltk.download("stopwords")
nltk.download("punkt_tab")

# ==============================#


# =============================
# 1. Leitura e jun√ß√£o dos dados
# =============================
ratings = pd.read_csv("Books_rating.csv")
books = pd.read_csv("books_data.csv")
# df = pd.read_csv("avaliacoes_processadas.csv")

# Espiar os dados as colunas do DataFrame
# Campos ou features (caracter√≠sticas) ou atributos.
print("Tamanho das bases:", ratings.shape, books.shape)
# Tamanho das bases: (3000000, 9) (212404, 10)

print("Cabe√ßalho dos Books:", books["Title"].head(10))
print("Cabe√ßalho dos Ratings:", ratings["Title"].head(10))

# A base de livros (books) est√° bem normalizada,
# sem repeti√ß√µes de t√≠tulo.
# Isso afeta os joins com a base de
# avalia√ß√µes (ratings):
# ‚ö†Ô∏è Se t√≠tulos repetidos existissem,
# teriamos que desambiguar por autor, edi√ß√£o, etc.
# Ajuda na hora de fazer buscas, matching e FAISS,
# pois garante consist√™ncia dos t√≠tulos.
books["Title"].describe()
# count     212403
# unique    212403
# top       Its Only Art If Its Well Hung!
# freq      1

# A base ratings cont√©m avalia√ß√µes de usu√°rios,
# com repeti√ß√£o de t√≠tulos, um mesmo livro pode
# receber muitas avalia√ß√µes.
# H√° exatamente 212.403 t√≠tulos distintos, o que coincide
# com a base books. Mas:
# Isso n√£o garante que todos os t√≠tulos estejam
# em ambas as bases.
# √â necess√°rio cruzamento (merge) para identificar t√≠tulos
# que s√≥ aparecem em uma base.
# freq = 22023 para The Hobbit	Esse livro √© extremamente
# popular, √∫til para an√°lise de sentimento
# H√° uma pequena quantidade de linhas (208) sem t√≠tulo,

# üß† A base de ratings √© muito rica e densa, com milh√µes de
# avalia√ß√µes de usu√°rios.
# Embora tenhamos 212403 mil livros √∫nicos avaliados, h√° uma
# alta concentra√ß√£o de reviews em alguns t√≠tulos
# populares (como "The Hobbit").
# H√° uma pequena quantidade de linhas (208) sem t√≠tulo,
# que podem ser filtradas e analisadas no futuro me de 1%

ratings["Title"].describe()
# count        2999792
# unique        212403
# top       The Hobbit
# freq           22023
# linhas (208) sem t√≠tulo

# ratings.shape
# ratings["Title"].isna() | (ratings["Title"].str.strip() == '')
ratings["Title"].isna().sum()
books["Title"].isna().sum()
ratings_Nulos = ratings[ratings["Title"].isna()].copy()
ratings_Nulos.to_csv("ratings_Nulos.csv", index=False)
books.loc[:10, "Title"]
ratings.loc[:10, "Title"]

# Um caso para teste de merge
ratings.loc[ratings["Title"] == "The Hobbit"]

# Normaliza√ß√£o dos t√≠tulos para facilitar o merge
ratings["Title_clean"] = ratings["Title"].str.strip().str.lower()
books["Title_clean"] = books["Title"].str.strip().str.lower()

# Normaliza√ß√£o dos authors e categories, lista para texto
books["authors"] = books["authors"].apply(
    lambda x: ", ".join(ast.literal_eval(x)) if isinstance(x, str) else x
)
books["categories"] = books["categories"].apply(
    lambda x: ", ".join(ast.literal_eval(x)) if isinstance(x, str) else x
)
books["categories"].head(3)


# Merge via t√≠tulo normalizado
df = pd.merge(
    ratings, books, on="Title_clean", how="left", suffixes=("_rating", "_book")
)
df.shape
# Via Left Join (3320453, 20) Avaliar diferen√ßa se significativa

df = pd.merge(
    ratings, books, on="Title_clean", how="inner", suffixes=("_rating", "_book")
)
df.shape
# Via Inner Join (3320453, 20)

# Espiar os dados do join, colunas limpas
df.loc[:3, ["authors", "categories", "Title_clean"]]
print("Tamanho das bases:", df.shape, ratings.shape, books.shape, end="\n")
# Tamanho das bases: df (3320453, 20) ratings (3000000, 10) books (212404, 11)

# word_tokenize("text to test")
df3 = df.copy()
# df = df3.copy()
# df = df.loc[:100000,].copy()

# =============================
# 2. Limpeza de texto (coluna 'text')
# =============================
stop_words = set(stopwords.words("english"))


def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"[^\w\s]", "", text)
    tokens = word_tokenize(text)
    tokens = [w for w in tokens if w not in stop_words]
    return " ".join(tokens)


# 2. Limpeza de texto - word_tokenize -- stop_words
df["review_clean"] = df["text"].fillna("").apply(clean_text)


# =============================
# 3. An√°lise de sentimento
# =============================
def get_sentiment(text):
    try:
        return TextBlob(text).sentiment.polarity
    except:
        return 0


# Analise de Sentimentos da Coluna Text
df["sentiment"] = df["text"].fillna("").apply(get_sentiment)

# Sentimento Geral das Avalia√ß√µes
# Foram analisadas 3,3 milh√µes de reviews com NLP.
# A m√©dia de sentimento √© +0,21, indicando tend√™ncia positiva.
# 25% das avalia√ß√µes t√™m sentimento quase neutro (< 0,10).
# H√° presen√ßa de cr√≠ticas fortemente negativas (m√≠nimo = -1), mas s√£o minoria.
# A dispers√£o dos dados mostra uma base rica para extra√ß√£o de insights.
# üëâ Isso permite priorizar avalia√ß√µes negativas para corre√ß√µes e
# identificar f√£s para a√ß√µes de marketing.

df["sentiment"].describe()
# count    3.320453e+06
# mean     2.098236e-01
# std      1.947297e-01
# min     -1.000000e+00
# 25%      9.598966e-02
# 50%      1.927083e-01
# 75%      3.092105e-01
# max      1.000000e+00

# =============================
# 4. Visualiza√ß√µes
# =============================

# Distribui√ß√£o de notas
# Este gr√°fico mostra a distribui√ß√£o geral
# das notas que os leitores deram aos livros
# analisados.
# Cada barra representa a quantidade de avalia√ß√µes
# dentro de uma faixa de nota (score),
# variando de 1 a 5.
# üìå Por que isso importa:
# Ele nos ajuda a entender se os leitores, no geral,
# est√£o satisfeitos ou insatisfeitos com os livros.
# Por exemplo, um pico em notas 4 e 5 indica boa
# aceita√ß√£o, enquanto muitas notas abaixo de 3
# alertam para poss√≠veis problemas de conte√∫do,
# posicionamento ou expectativas.
plt.figure(figsize=(6, 4))
sns.histplot(df["score"], bins=5, kde=False)
plt.title("Rating Distribution")
plt.xlabel("Score")
plt.ylabel("Frequency")
plt.show()

# Top dez autores
# Este gr√°fico mostra como variam as avalia√ß√µes (notas) dos
# livros dos 3 autores mais avaliados.
# Cada barra horizontal representa o intervalo de notas recebidas pelos
# livros de um autor.
# O tra√ßo central representa a mediana (nota mais comum).
# As bordas da caixa indicam os 25% e 75% dos valores (distribui√ß√£o).
# Os pontos fora da caixa s√£o notas extremas (muito altas ou muito baixas).
# üìå Por que isso importa:
# Esse gr√°fico permite identificar autores com avalia√ß√µes mais consistentes
# (caixas menores) ou mais pol√™micos (caixas grandes ou com muitos outliers).
# Isso ajuda na curadoria de autores para campanhas, destaques ou reavalia√ß√£o editorial.
df["authors"] = df["authors"].astype(str)
top_authors = df["authors"].value_counts().nlargest(10).index
plt.figure(figsize=(10, 5))
sns.boxplot(data=df[df["authors"].isin(top_authors)], x="authors", y="score")
plt.title("Score Distribution by Top Authors")
plt.xticks(rotation=45)
plt.show()

# books["authors"].isna().sum()
# sem_autor = books["authors"].isna() | (books["authors"].str.strip() == "")
# print("Total de livros sem autor:", sem_autor.sum())

# Quantos livros est√£o sem autor identificado:
books["authors"] = books["authors"].fillna("")
sem_autor = books["authors"].str.strip() == ""
print("Total de livros sem autor:", sem_autor.sum())
# Total de livros sem autor: 31414

# Top 10 Sentimento por categoria
# Este gr√°fico mostra como os leitores se sentem, em m√©dia,
# sobre os livros de cada uma das 10 categorias mais populares.
# Aqui n√£o estamos olhando para a nota, mas sim para o tom emocional
# da avalia√ß√£o textual ‚Äî se a linguagem usada √© positiva, neutra ou negativa.
# Os valores v√£o de -1.0 (muito negativo) at√© +1.0 (muito positivo):
# A mediana mostra o sentimento mais comum.
# A largura da caixa mostra a diversidade de sentimentos.
# üìå Por que isso importa:
# Isso nos permite detectar g√™neros com maior carga emocional
# positiva ou negativa.
# Por exemplo, categorias com sentimento consistentemente positivo
# indicam alta satisfa√ß√£o ‚Äî mesmo que a nota n√£o seja a mais alta.
# J√° categorias com grande varia√ß√£o de sentimento (ou tendendo ao negativo)
# podem sinalizar que os livros geram frustra√ß√£o ou s√£o mal compreendidos.

# df["categories"] = df["categories"].astype(str)
# top_cats = df["categories"].value_counts().nlargest(10).index
# plt.figure(figsize=(10, 5))
# sns.boxplot(data=df[df["categories"].isin(top_cats)], x="categories", y="sentiment")
# plt.title("Sentiment by Book Category")
# plt.xticks(rotation=45)
# plt.show()

import matplotlib.pyplot as plt

top_categorias = df["categories"].value_counts().nlargest(10).index
df_top_categorias = df[df["categories"].isin(top_categorias)]
contagem = df_top_categorias["categories"].value_counts()

contagem.plot(kind="barh", figsize=(8, 5))
plt.title("Top 10 Categorias com Mais Livros")
plt.xlabel("Quantidade de livros")
plt.gca().invert_yaxis()  # categorias mais populares no topo
plt.tight_layout()
plt.show()

books["categories"] = books["categories"].fillna("")
sem_categories = books["categories"].str.strip() == ""
print("Total de livros sem categories:", sem_categories.sum())
# Total de livros sem categories: 41199

# Top 10 Sentimento por editora
df["publisher"] = df["publisher"].astype(str)
top_publisher = df["publisher"].value_counts().nlargest(10).index
df_top_publisher = df[df["publisher"].isin(top_publisher)]
contagem = df_top_publisher["publisher"].value_counts()

books["publisher"] = books["publisher"].fillna("")
sem_publisher = books["publisher"].str.strip() == ""
print("Total de livros sem publisher:", sem_publisher.sum())
# Total de livros sem publisher: 75886

contagem.plot(kind="barh", figsize=(8, 5))
plt.title("Top 10 publisher com Mais Livros")
plt.xlabel("Quantidade de livros")
plt.gca().invert_yaxis()  # publisher mais populares no topo
plt.tight_layout()
plt.show()

# =============================
# 5. Wordclouds
# =============================

# Extrair da base os 3 livros mais contradit√≥rios em dois cen√°rios:
# 1. Nota alta (score ‚â• 4.5) + Sentimento negativo (sentiment ‚â§ 0)
# 2. Nota baixa (score ‚â§ 2.5) + Sentimento positivo (sentiment ‚â• 0.3)
# Esses casos s√£o valiosos para:
# Identificar livros mal avaliados por engano (ex: review positiva, mas nota baixa)
# Detectar leitores que gostaram da experi√™ncia mas deram nota baixa por um
# fator espec√≠fico
# Entender ambiguidade entre o texto e a nota
# Top 3 casos com nota alta, mas sentimento negativo
caso1 = (
    df[(df["score"] >= 4.5) & (df["sentiment"] <= 0)]
    .sort_values(by="sentiment")
    .head(3)
)
# üü¶ Notas Altas com Sentimentos Negativos
# üìò T√≠tulo: in dark places
# üë§ Usu√°rio: Creepee
# ‚≠ê Score: 5.0 | üß† Sentimento: -1.0
# üìù Resumo: Great book!
# üí¨ Texto:
# Another well written book by Michael Prescott! Makes you keep guessing
# and just when you think you know who the bad guy is...nope you don't!!...


# Top 3 casos com nota baixa, mas sentimento positivo
caso2 = (
    df[(df["score"] <= 2.5) & (df["sentiment"] >= 0.3)]
    .sort_values(by="sentiment", ascending=False)
    .head(3)
)


# üß† Interpreta√ß√£o de Neg√≥cio
# üîç Alerta de inconsist√™ncia: pode indicar erro de nota, ou avalia√ß√£o emocionalmente complexa
# üìà √ötil para entrevistas: leitores que expressam sentimentos positivos apesar de nota baixa trazem insights ricos
# ü§ñ Relevante para fine-tuning de LLM: melhora detec√ß√£o de ironia, ambiguidade e contexto
def mostrar_casos(df_casos, titulo):
    print(f"\nüü¶ {titulo}")
    for i, row in df_casos.iterrows():
        print(f"\nüìò T√≠tulo: {row['Title_clean']}")
        print(f"üë§ Usu√°rio: {row['profileName']}")
        print(f"‚≠ê Score: {row['score']} | üß† Sentimento: {round(row['sentiment'], 3)}")
        print(f"üìù Resumo: {row['summary']}")
        print(f"üí¨ Texto:\n{row['text'][:500]}...\n{'-'*80}")


mostrar_casos(caso1, "Notas Altas com Sentimentos Negativos")
mostrar_casos(caso2, "Notas Baixas com Sentimentos Positivos")


def plot_wordcloud(text, title):
    wc = WordCloud(width=800, height=400, background_color="white").generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.title(title)
    plt.show()


# Positivas
positive_text = " ".join(df[df["sentiment"] > 0.3]["review_clean"].tolist())
plot_wordcloud(positive_text, "Frequent Words in Positive Reviews")

# Negativas
negative_text = " ".join(df[df["sentiment"] < -0.1]["review_clean"].tolist())
plot_wordcloud(negative_text, "Frequent Words in Negative Reviews")

# =============================
# 6. Exportar base processada
# =============================

df.to_csv("avaliacoes_processadas2.csv", index=False)
