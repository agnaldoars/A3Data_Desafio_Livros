# EDA_NLP_Livros.py

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from textblob import TextBlob
from wordcloud import WordCloud
import ast

nltk.download("punkt")
nltk.download("stopwords")
# ==============================#


# =============================
# 1. Leitura e junÃ§Ã£o dos dados
# =============================

ratings = pd.read_csv("Books_rating.csv")
books = pd.read_csv("books_data.csv")

# Espiar os dados
print("Tamanho das bases:", ratings.shape, books.shape)

print("Describe Ratings:", ratings.describe)
print("Describe Books:", books.describe)

print("CabeÃ§alho dos Books:", books.head(10))
print("CabeÃ§alho dos Ratings:", ratings.head(10))

books.loc[:10, "Title"]
ratings.loc[:10, "Title"]

# Um caso para teste de merge
ratings.loc[ratings["Title"] == "Its Only Art If Its Well Hung!"]

# NormalizaÃ§Ã£o dos tÃ­tulos para facilitar o merge
ratings["Title_clean"] = ratings["Title"].str.strip().str.lower()
books["Title_clean"] = books["Title"].str.strip().str.lower()

# NormalizaÃ§Ã£o dos authors e categories, lista para texto
books["authors"] = books["authors"].apply(
    lambda x: ", ".join(ast.literal_eval(x)) if isinstance(x, str) else x
)
books["categories"] = books["categories"].apply(
    lambda x: ", ".join(ast.literal_eval(x)) if isinstance(x, str) else x
)
books["categories"].head(3)

# Merge via tÃ­tulo normalizado
df = pd.merge(
    ratings, books, on="Title_clean", how="left", suffixes=("_rating", "_book")
)

# Espiar os dados do join
df.loc[:10]
print("Tamanho das bases:", df.shape, ratings.shape, books.shape)


# =============================
# 2. Limpeza de texto (coluna 'text')
# =============================

stop_words = set(stopwords.words("english"))

nltk.download("punkt_tab")


def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"[^\w\s]", "", text)
    tokens = word_tokenize(text)
    tokens = [w for w in tokens if w not in stop_words]
    return " ".join(tokens)


# word_tokenize("text to test")
df3 = df.copy()
# df = df3.copy()

# df3 = df.loc[:1000,].copy()
# ver colunas atuais e na base reduzida
df.columns
df["review_clean"] = df["text"].fillna("").apply(clean_text)

# =============================
# 3. AnÃ¡lise de sentimento
# =============================


def get_sentiment(text):
    try:
        return TextBlob(text).sentiment.polarity
    except:
        return 0


df["sentiment"] = df["text"].fillna("").apply(get_sentiment)

df.loc[:10, ["sentiment"]]
# =============================
# 4. VisualizaÃ§Ãµes
# =============================

# DistribuiÃ§Ã£o de notas
# Este grÃ¡fico mostra a distribuiÃ§Ã£o geral das notas que os leitores deram aos livros analisados.
# Cada barra representa a quantidade de avaliaÃ§Ãµes dentro de uma faixa de nota (score), variando de 1 a 5.
# ðŸ“Œ Por que isso importa:
# Ele nos ajuda a entender se os leitores, no geral, estÃ£o satisfeitos ou insatisfeitos com os livros.
# Por exemplo, um pico em notas 4 e 5 indica boa aceitaÃ§Ã£o, enquanto muitas notas abaixo de 3 alertam para possÃ­veis problemas de conteÃºdo, posicionamento ou expectativas.
plt.figure(figsize=(6, 4))
sns.histplot(df["score"], bins=5, kde=False)
plt.title("Rating Distribution")
plt.xlabel("Score")
plt.ylabel("Frequency")
plt.show()

# Top dez autores
# Este grÃ¡fico mostra como variam as avaliaÃ§Ãµes (notas) dos livros dos 10 autores mais avaliados.
# Cada barra horizontal representa o intervalo de notas recebidas pelos livros de um autor.
# O traÃ§o central representa a mediana (nota mais comum).
# As bordas da caixa indicam os 25% e 75% dos valores (distribuiÃ§Ã£o).
# Os pontos fora da caixa sÃ£o notas extremas (muito altas ou muito baixas).
# ðŸ“Œ Por que isso importa:
# Esse grÃ¡fico permite identificar autores com avaliaÃ§Ãµes mais consistentes (caixas menores) ou mais polÃªmicos (caixas grandes ou com muitos outliers).
# Isso ajuda na curadoria de autores para campanhas, destaques ou reavaliaÃ§Ã£o editorial.
df["authors"] = df["authors"].astype(str)
top_authors = df["authors"].value_counts().nlargest(10).index
plt.figure(figsize=(10, 5))
sns.boxplot(data=df[df["authors"].isin(top_authors)], x="authors", y="score")
plt.title("Score Distribution by Top Authors")
plt.xticks(rotation=45)
plt.show()


# plt.figure(figsize=(6, 4))
# ax = sns.histplot(df["score"], bins=5, kde=False)
#
## Adiciona os valores no topo de cada barra
# for p in ax.patches:
#    height = p.get_height()
#    ax.text(
#        p.get_x() + p.get_width() / 2,     # posiÃ§Ã£o x (centro da barra)
#        height + 0.5,                      # posiÃ§Ã£o y (acima da barra)
#        f"{int(height)}",                  # texto com valor inteiro
#        ha="center"                        # alinhamento horizontal
#    )
#
# plt.title("Rating Distribution")
# plt.xlabel("Score")
# plt.ylabel("Frequency")
# plt.tight_layout()
# plt.show()

# Top 10 Sentimento por categoria
# Este grÃ¡fico mostra como os leitores se sentem, em mÃ©dia, sobre os livros de cada uma das 10 categorias mais populares.
# Aqui nÃ£o estamos olhando para a nota, mas sim para o tom emocional da avaliaÃ§Ã£o textual â€” se a linguagem usada Ã© positiva, neutra ou negativa.
# Os valores vÃ£o de -1.0 (muito negativo) atÃ© +1.0 (muito positivo):
# A mediana mostra o sentimento mais comum.
# A largura da caixa mostra a diversidade de sentimentos.
# ðŸ“Œ Por que isso importa:
# Isso nos permite detectar gÃªneros com maior carga emocional positiva ou negativa.
# Por exemplo, categorias com sentimento consistentemente positivo indicam alta satisfaÃ§Ã£o â€” mesmo que a nota nÃ£o seja a mais alta.
# JÃ¡ categorias com grande variaÃ§Ã£o de sentimento (ou tendendo ao negativo) podem sinalizar que os livros geram frustraÃ§Ã£o ou sÃ£o mal compreendidos.

df["categories"] = df["categories"].astype(str)
top_cats = df["categories"].value_counts().nlargest(10).index
plt.figure(figsize=(10, 5))
sns.boxplot(data=df[df["categories"].isin(top_cats)], x="categories", y="sentiment")
plt.title("Sentiment by Book Category")
plt.xticks(rotation=45)
plt.show()

# =============================
# 5. Wordclouds
# =============================

# Extrair da base os 3 livros mais contraditÃ³rios em dois cenÃ¡rios:
# 1. Nota alta (score â‰¥ 4.5) + Sentimento negativo (sentiment â‰¤ 0)
# 2. Nota baixa (score â‰¤ 2.5) + Sentimento positivo (sentiment â‰¥ 0.3)
# Esses casos sÃ£o valiosos para:
# Identificar livros mal avaliados por engano (ex: review positiva, mas nota baixa)
# Detectar leitores que gostaram da experiÃªncia mas deram nota baixa por um fator especÃ­fico
# Entender ambiguidade entre o texto e a nota
# Top 3 casos com nota alta, mas sentimento negativo
caso1 = (
    df[(df["score"] >= 4.5) & (df["sentiment"] <= 0)]
    .sort_values(by="sentiment")
    .head(3)
)

# Top 3 casos com nota baixa, mas sentimento positivo
caso2 = (
    df[(df["score"] <= 2.5) & (df["sentiment"] >= 0.3)]
    .sort_values(by="sentiment", ascending=False)
    .head(3)
)


# ðŸ§  InterpretaÃ§Ã£o de NegÃ³cio
# ðŸ” Alerta de inconsistÃªncia: pode indicar erro de nota, ou avaliaÃ§Ã£o emocionalmente complexa
# ðŸ“ˆ Ãštil para entrevistas: leitores que expressam sentimentos positivos apesar de nota baixa trazem insights ricos
# ðŸ¤– Relevante para fine-tuning de LLM: melhora detecÃ§Ã£o de ironia, ambiguidade e contexto
def mostrar_casos(df_casos, titulo):
    print(f"\nðŸŸ¦ {titulo}")
    for i, row in df_casos.iterrows():
        print(f"\nðŸ“˜ TÃ­tulo: {row['Title_clean']}")
        print(f"ðŸ‘¤ UsuÃ¡rio: {row['profileName']}")
        print(f"â­ Score: {row['score']} | ðŸ§  Sentimento: {round(row['sentiment'], 3)}")
        print(f"ðŸ“ Resumo: {row['summary']}")
        print(f"ðŸ’¬ Texto:\n{row['text'][:500]}...\n{'-'*80}")


mostrar_casos(caso1, "Notas Altas com Sentimentos Negativos")
mostrar_casos(caso2, "Notas Baixas com Sentimentos Positivos")


def plot_wordcloud(text, title):
    wc = WordCloud(width=800, height=400, background_color="white").generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.title(title)
    plt.show()


# Positivas
positive_text = " ".join(df[df["sentiment"] > 0.3]["review_clean"].tolist())
plot_wordcloud(positive_text, "Frequent Words in Positive Reviews")

# Negativas
negative_text = " ".join(df[df["sentiment"] < -0.1]["review_clean"].tolist())
plot_wordcloud(negative_text, "Frequent Words in Negative Reviews")

# =============================
# 6. Exportar base processada
# =============================

df.to_csv("avaliacoes_processadas.csv", index=False)
